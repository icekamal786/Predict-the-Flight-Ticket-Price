{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffef87a9",
   "metadata": {},
   "source": [
    "# <span style=\"color:Blue\"><center>Predict The Flight Ticket Price Hackathon</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a994f79",
   "metadata": {},
   "source": [
    "## <span style=\"color:Blue\">Introduction</span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dc5f8f5c",
   "metadata": {},
   "source": [
    "Flight ticket prices can be something hard to guess, today we might see a price, check out the price of the same flight tomorrow, it will be a different story. We might have often heard travellers saying that flight ticket prices are so unpredictable. Huh! Here I have taken the challenge! As data scientists, I am gonna build a best model to predict price of flight with required details. Here I have prices of flight tickets for various airlines between the months of March and June of 2019 and between various cities. I have used these data to train my model.    \n",
    "\n",
    "Size of training set: 10683 \n",
    "records Size of test set: 2671 records "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f82fc5",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Features</span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bfe1af3",
   "metadata": {},
   "source": [
    "Airline: The name of the airline. \n",
    "Date_of_Journey: The date of the journey Source: The source from which the service begins. \n",
    "Destination: The destination where the service ends. \n",
    "Route: The route taken by the flight to reach the destination. \n",
    "Dep_Time: The time when the journey starts from the source. \n",
    "Arrival_Time: Time of arrival at the destination. \n",
    "Duration: Total duration of the flight. \n",
    "Total_Stops: Total stops between the source and destination. \n",
    "Additional_Info: Additional information about the flight. \n",
    "Price: The price of the ticket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850cc12a",
   "metadata": {},
   "source": [
    "## <span style=\"color:Blue\">Objective</span>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25af339b",
   "metadata": {},
   "source": [
    "Prediction of price of flight tickets for various airlines between the months of March and June and between various cities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9809279e",
   "metadata": {},
   "source": [
    "## <span style=\"color:Blue\">Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f95d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Used for working with arrays.\n",
    "# Pandas: It is made mainly for working with relational or labeled data both easily and intuitively. \n",
    "# It provides various data structures and operations for manipulating numerical data and time series.\n",
    "import pandas as pd # It is used to analyze data\n",
    "# Seaborn mostly used for statistical plotting in Python. \n",
    "# It is built on top of Matplotlib and provides beautiful default styles and color palettes to make statistical plots more attractive.\n",
    "import seaborn as sns\n",
    "import plotly.express as px # Contain a function that cretae entire figure at once.\n",
    "import matplotlib.pyplot as plt # Amazing visualization library in Python for 2D plots of arrays.\n",
    "import warnings # Warning is useful to alert the user of some condition in a program, where that condition (normally) doesn't warrant raising an exception and terminating the program.\n",
    "warnings.filterwarnings('ignore') # To ignore all warnings by setting ‘ignore’ as a parameter.\n",
    "print('Libraries imported') \n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b2de7",
   "metadata": {},
   "source": [
    "## <span style=\"color:Blue\">Data Preparation</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file and create dataframe\n",
    "train_df = pd.read_excel('Data_Train.xlsx') # Read train file\n",
    "test_df= pd.read_excel('Test_set.xlsx') # Read test file\n",
    "sub_df=pd.read_excel('Sample_submission.xlsx') # Required format for submission in Hackathon\n",
    "# Copy the dataframe for further use\n",
    "df = train_df.copy()\n",
    "df1 = test_df.copy()\n",
    "df2 = sub_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # To see the fisrt 5 rows of training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10) # 10 random sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1264451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head() # To see the fisrt 5 rows of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc80f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head() # To see the first 5 rows of submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c7180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # To get the information of dataset, type of features, memory uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99985efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # To check the shape of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # To describe the data frame (only price is numerical data, others are object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1403b8b5",
   "metadata": {},
   "source": [
    "#### Missings And Duplicates Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d66d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows of each attributes for which the value is NULL.\n",
    "print(df.isna().sum().sort_values(ascending = False))\n",
    "# Print number of duplicate rows considering all column features in dataframe\n",
    "print('Number of Duplicate Values in df : ' ,df.duplicated().sum() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c509a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates() # Delete all the duplicate rows considering all column wise.\n",
    "df.shape # Shape of data frame is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value check in plot\n",
    "# !pip install missingno # first required to install this library \n",
    "import missingno as msno\n",
    "\n",
    "fig = plt.figure(figsize=(15,7)) # Size of complete figure\n",
    "# Normal Axis\n",
    "ax1 = fig.add_subplot(1,2,1) # Created subplots in 1 rows and 2 columns\n",
    "msno.bar(df, color=\"tomato\", fontsize=12, ax=ax1); # Define size of bar\n",
    "# Logrithmic Y-Axis\n",
    "ax2 = fig.add_subplot(1,2,2) # Created subplots in 1 rows and 2 columns\n",
    "msno.bar(df, log=True, color=\"tab:green\", fontsize=12, ax=ax2); # Define size of bar\n",
    "\n",
    "plt.tight_layout() # Show the layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the missing value of route and total stops from same row or not\n",
    "df[df['Route'].isna() | df['Total_Stops'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66653229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null values\n",
    "df.dropna(inplace= True)\n",
    "# Check null values again\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd380e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of rows of each attributes for which the value is NULL.\n",
    "print(df.isna().sum().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ec6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba112ed",
   "metadata": {},
   "source": [
    "## <span style=\"color:Blue\">EDA & Feature Engineering</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08bb81",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Features Engineering</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3934d11",
   "metadata": {},
   "source": [
    "### Convert Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf323c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Duration coulumn into minutes\n",
    "def convert_duration(duration):\n",
    "    if len(duration.split())==2:\n",
    "        hours = int(duration.split()[0][:-1]) # 1st index of duration is hour\n",
    "        minutes= int(duration.split()[1][:-1]) # 2nd index of duration is minutes\n",
    "        return hours*60+minutes # Convert all into minutes\n",
    "    else:\n",
    "        return int(duration[:-1])*60 # If no hour index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe55be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the conversion function\n",
    "df['Duration_in_Minutes'] = df['Duration'].apply(convert_duration)\n",
    "# Drop the previous useless column\n",
    "df.drop(['Duration'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd06430",
   "metadata": {},
   "source": [
    "### Departure Time & Arrival Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype of dep and arrival time into datetime format\n",
    "df['Dep_Time']=pd.to_datetime(df['Dep_Time'])\n",
    "df['Arrival_Time']=pd.to_datetime(df['Arrival_Time'])\n",
    "# Data Types of features\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create departure and arrival time into minute and hour into different column\n",
    "df['Dep_Time_in_hours'] = df['Dep_Time'].dt.hour\n",
    "df['Dep_Time_in_minutes'] = df['Dep_Time'].dt.minute\n",
    "df['Arrival_Time_in_hours'] = df['Arrival_Time'].dt.hour\n",
    "df['Arrival_Time_in_minutes'] = df['Arrival_Time'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139265ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99a78d7b",
   "metadata": {},
   "source": [
    "Now there is no use of Arrival_Time and Dep_Time Features, because We already converted it. So, I am dropping both the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff433e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop Dep_Time and Arrival_Time features\n",
    "df.drop(['Dep_Time','Arrival_Time'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c85ef",
   "metadata": {},
   "source": [
    "### Date of Journey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data type into datetime format\n",
    "df['Date_of_Journey']=pd.to_datetime(df['Date_of_Journey'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d8b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check, weather year of date of journey is unique or not.\n",
    "df['Date_of_Journey'].dt.year.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "349b7272",
   "metadata": {},
   "source": [
    "Here uniqueness in year, So we only need to make two column of months and days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a40c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted day and month column from Date_of_Journey column\n",
    "df['Day']= df['Date_of_Journey'].dt.day\n",
    "df['Month']= df['Date_of_Journey'].dt.month\n",
    "# Drop the useless column Date_of_Journey\n",
    "df.drop(['Date_of_Journey'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332b13f",
   "metadata": {},
   "source": [
    "### Additional Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the category in Additional_Info feature\n",
    "df['Additional_Info'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0f80d2c",
   "metadata": {},
   "source": [
    "Since more than 80% row have no info. So I have dropped this useless feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef98b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Additional_Info feature\n",
    "df.drop('Additional_Info', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f2d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of features which datatype = Object\n",
    "df.select_dtypes(['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9956c5b",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Univariate Analysis with Categorical Features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ec571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis with categorical features \n",
    "# ('Airline', 'Source', 'Destination', 'Total_Stops', 'Route')\n",
    "for i in ['Airline', 'Source', 'Destination', 'Total_Stops','Route']:\n",
    "    plt.figure(figsize=(25,12))\n",
    "    sns.countplot(data=df, x=i)\n",
    "    axis = sns.countplot(x=i,data=df.sort_values('Price',ascending=True))\n",
    "    axis.set_xticklabels(axis.get_xticklabels(), rotation=40, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1574641b",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24669315",
   "metadata": {},
   "source": [
    "- Less number of booking for airlines; Vistara Premium Economy, Multiple Carriers Premium Economy and Jet Airways Business. High number of booking for airlines; Air India, Jet Airways.\n",
    "- There are large number booking has done as a source for Delhi and Banglore, and destination at Delhi and Cochin.\n",
    "- There are very less number of booking for airlines having 3 and 4 total stops, maximum booking has done for total stops of 1.\n",
    "- There are very large number of routes having 1 or 2 stops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4813c1",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Bivariate Analysis with Categorical Features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bf884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Analysis of categorical features with Price (Bar Plot)\n",
    "for i in ['Airline', 'Source', 'Destination', 'Total_Stops', 'Route']:\n",
    "    plt.figure(figsize=(25,12))\n",
    "    axis = sns.barplot(x=i,y='Price',data=df.sort_values('Price',ascending=True))\n",
    "    axis.set_xticklabels(axis.get_xticklabels(), rotation=40, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5022e",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51d19ea9",
   "metadata": {},
   "source": [
    "- Price of Jet Airways Business very high around 58K.\n",
    "- Price is high for total stops of 4 in the journey.\n",
    "- We can't judge price only based on one feature source(bivariate analysis), destination, routes, or total stops. It will give wrong judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8531834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot \n",
    "for i in ['Airline', 'Source', 'Destination', 'Total_Stops','Route']:\n",
    "    plt.figure(figsize=(20,9))\n",
    "    axis = sns.boxplot(x=i,y='Price', data=df.sort_values('Price',ascending=True))\n",
    "    axis.set_xticklabels(axis.get_xticklabels(), rotation=40, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a5da2",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6311bb8f",
   "metadata": {},
   "source": [
    "- From the box plot, we can observe range of price for each airline, routes, total stops. \n",
    "- Only based on one of two features (Source and Destination), we can't examine the range of price.\n",
    "- There are some outliers in price for each features. I am not removing the outliers because it may helpful for the numerical/continuous features in regression model. After completion of encoding, based on the numerical/ continuous features. I will remove the outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9a6696",
   "metadata": {},
   "source": [
    "### Total Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency of each category of Total_Stops\n",
    "df['Total_Stops'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b53b9595",
   "metadata": {},
   "source": [
    "As this is case of Ordinal Categorical type, I perform LabelEncoder. Here, values are assigned with corresponding keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f697f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "df['Total_Stops']=df['Total_Stops'].map({\n",
    "    'non-stop':0,\n",
    "    '1 stop':1,\n",
    "    '2 stops':2,\n",
    "    '3 stops':3,\n",
    "    '4 stops':4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3ead2",
   "metadata": {},
   "source": [
    "#### Parallel Coordinates Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand the source and destination considering total stops\n",
    "## Creating parallel categories chart\n",
    "# Import go \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# Create dimensions\n",
    "# Source\n",
    "source_dim = go.parcats.Dimension(\n",
    "    values=df[\"Source\"], categoryorder=\"category ascending\", label=\"Source\"\n",
    ")\n",
    "# Airline\n",
    "airline_dim = go.parcats.Dimension(\n",
    "    values=df[\"Airline\"], label=\"Airline\"\n",
    ")\n",
    "# Destination\n",
    "destination_dim = go.parcats.Dimension(\n",
    "    values=df[\"Destination\"], label=\"Destination\"\n",
    ")\n",
    "# Total Stops\n",
    "total_stops_dim = go.parcats.Dimension(\n",
    "    values=df[\"Total_Stops\"],\n",
    "    label=\"Total Stops\",\n",
    "    categoryarray=[0,1,2,3,4],\n",
    "    ticktext=[\"non-stop\", \"1-stop\", \"2-stops\", \"3-stops\", \"4-stops\"],\n",
    ")\n",
    "# Create parcats trace\n",
    "color = df[\"Total_Stops\"]\n",
    "#colorscale = [[0, 'green'], [0.5, 'red'], [1.0, 'rgb(0, 0, 255)']]\n",
    "colorscale = 'Electric'\n",
    "#colorscale = px.colors.diverging.Tealrose\n",
    "# create figure object\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Parcats(\n",
    "            dimensions=[\n",
    "                source_dim,\n",
    "                destination_dim,\n",
    "                airline_dim,\n",
    "                total_stops_dim\n",
    "            ],\n",
    "            line={\"color\": color, \"colorscale\": colorscale},\n",
    "            hoveron=\"color\",\n",
    "            hoverinfo=\"count + probability\",\n",
    "            labelfont={\"size\": 18, \"family\": \"Times\"},\n",
    "            tickfont={\"size\": 16, \"family\": \"Times\"},\n",
    "            arrangement=\"freeform\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "# display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df38892",
   "metadata": {},
   "source": [
    "#### Insights"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3984277",
   "metadata": {},
   "source": [
    "- This plot is clearly showing, there is no other destination from Mumbai except Hyderabad with maximum not stop airlines.\n",
    "- There is only one destination 'Cochin' from Delhi with maximum of 1-stop with different Airlines.\n",
    "- There is only one destination 'Kolkata' from Chennai with maximum of non-stop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b53a9",
   "metadata": {},
   "source": [
    "### Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2524c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the frequency of each category in Airline\n",
    "df['Airline'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ae6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the airlines with average value of price\n",
    "df.groupby('Airline').describe()['Price'].sort_values('mean', ascending =False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a515ef7",
   "metadata": {},
   "source": [
    "For this particular feature, I have used one-hot encoding. Because, the total number of features are less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a97dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding: Create new column for each category of Airline Feature\n",
    "Airline = pd.get_dummies(df['Airline'], drop_first=True)\n",
    "Airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a393823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate Airline dataframe with main dataframe.\n",
    "df = pd.concat([df, Airline], axis = 1)\n",
    "# Drop useless column Airline\n",
    "df.drop('Airline', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77adb103",
   "metadata": {},
   "source": [
    "### Source & Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73c4615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the frequency of each category of Source and Destination Features\n",
    "li = ['Source', 'Destination']\n",
    "for i in li:\n",
    "    print(df[[i]].value_counts(),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies of Source and Destination Feature\n",
    "df = pd.get_dummies(data=df, columns = li, drop_first= True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e3226",
   "metadata": {},
   "source": [
    "### Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded667fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the Route feature\n",
    "route = df[['Route']]\n",
    "route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb731ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total stops between source and destination\n",
    "df['Total_Stops'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f259d203",
   "metadata": {},
   "source": [
    "There are 5 kind of routes having non-stop, 1-stop, 2-stops, 3-stops, 4-stops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86009f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 new feature column for each stop.\n",
    "route['Route_1']=route['Route'].str.split('→').str[0]\n",
    "route['Route_2']=route['Route'].str.split('→').str[1]\n",
    "route['Route_3']=route['Route'].str.split('→').str[3]\n",
    "route['Route_4']=route['Route'].str.split('→').str[4]\n",
    "route['Route_5']=route['Route'].str.split('→').str[5]\n",
    "route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa3c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN value with None\n",
    "route.fillna('None', inplace=True)\n",
    "route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for i in range(1,6):\n",
    "    col = 'Route_'+ str(i)\n",
    "    route[col]=le.fit_transform(route[col]) # Transfer text into numeric form\n",
    "route.drop('Route', axis=1, inplace =True)\n",
    "route.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ab817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate Route Dataframe into main dataframe\n",
    "df = pd.concat([df, route], axis = 1)\n",
    "# Drop the useless feature Route now\n",
    "df.drop('Route',axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fontdicts for formatting figure text\n",
    "axtitle_dict = {'family': 'serif','color':  'red','weight': 'bold','size': 16}\n",
    "axlab_dict = {'family': 'serif', 'color': 'black','size': 14}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33149dfa",
   "metadata": {},
   "source": [
    "#### Filtering Numericals and Categoricals columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted categorical columns having non-unique value less than 50\n",
    "categ_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].nunique()<=50:\n",
    "        if col!='Price':\n",
    "            categ_columns.append(col) \n",
    "print('categorical numericals columns are {}'.format(categ_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracted numerical columns\n",
    "Num_cols = [col for col in df.columns if col not in categ_columns]\n",
    "print('numericals columns are {}'.format(Num_cols)) \n",
    "Num_cols.remove('Price') # Removing Price (output feature)\n",
    "Num_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f334f",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Univariate Analysis After Feature Engineering</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f8850",
   "metadata": {},
   "source": [
    "#### Distplot of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99395570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create figure with 3 x 3 grid of subplots\n",
    "fig = plt.figure(figsize=[15,12])\n",
    "fig.suptitle('DISTPLOT OF DATA', fontsize=18, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.92);\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4);\n",
    "for i ,col in enumerate(Num_cols):\n",
    "    ax = fig.add_subplot(1, 1, i+1)\n",
    "    ax = sns.distplot(df[col],  color='dodgerblue')\n",
    "    ax.axvline(df[col].quantile(q=0.25),color='green',linestyle='--',label='25% Quartile')\n",
    "    ax.axvline(df[col].mean(),color='red',linestyle='--',label='Mean')\n",
    "    ax.axvline(df[col].median(),color='black',linestyle='--',label='Median')\n",
    "    ax.axvline(df[col].quantile(q=0.75),color='blue',linestyle='--',label='75% Quartile')\n",
    "    # ax.text('skewness: {}' .format(str(round(df[col].skew(),3))), ha='right', va='center', size=11)\n",
    "    ax.set_xlabel(f'{col}', fontdict=axlab_dict)\n",
    "    ax.set_title(f'{col.upper()}    skewness {round(df[col].skew(),3)}', fontdict=axtitle_dict)\n",
    "    ax.legend(fontsize=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570cf784",
   "metadata": {},
   "outputs": [],
   "source": [
    "colours = ['forestgreen','dodgerblue','goldenrod', 'coral' , 'silver' , 'gold' , 'dodgerblue', 'green', 'red', 'blue'];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b5655",
   "metadata": {},
   "source": [
    "#### Outliers Detection in Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check of outliers by applying the IQR method checking if values are way outside the IQR borders.\n",
    "# Numerical_features = [\"Duration_in_Minutes\"]\n",
    "df_num = df[Num_cols]\n",
    "df_num.describe()\n",
    "\n",
    "Q1 = df_num.quantile(0.25)\n",
    "Q3 = df_num.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "IQR\n",
    "((df_num < (Q1 - 1.5 * IQR)) | (df_num > (Q3 + 1.5 * IQR))).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe07421",
   "metadata": {},
   "source": [
    "#### Visualization of outliers using box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6335969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 3 x 3 grid of subplots\n",
    "fig = plt.figure(figsize=[16,12])\n",
    "fig.suptitle('BOXPLOT OF DATA', fontsize=18, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.92);\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4);\n",
    "for i ,col in enumerate(Num_cols):  \n",
    "    ax1 = fig.add_subplot(1, 1, i+1);\n",
    "    ax1 = sns.boxplot(data = df, x=col ,  color= colours[i]);\n",
    " \n",
    "    ax1.set_title(f'{col}', fontdict=axtitle_dict) \n",
    "    ax1.set_xlabel(f'{col}', fontdict=axlab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5af0ad",
   "metadata": {},
   "source": [
    "#### Outliers Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a115d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the IQR For Duration_in_Minutes columns\n",
    "dict = {}\n",
    "for col in ['Duration_in_Minutes']:\n",
    "    percentile25 = df[col].quantile(0.25)\n",
    "    percentile75 = df[col].quantile(0.75)\n",
    "    IQR  = percentile75 - percentile25 \n",
    "    upper_limit = percentile75 + 1.5 * IQR \n",
    "    lower_limit = percentile25 - 1.5 * IQR\n",
    "    dict['upper_limit'+ '_' + col] = upper_limit\n",
    "    dict['lower_limit'+ '_' + col] = lower_limit "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1cc69680",
   "metadata": {},
   "source": [
    "In Above code cell i just created a dictionary to keep upper_limit and lower_limit of Duration_in_Minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a51787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find upper limit and lower limit\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274d877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data in the range\n",
    "for col in ['Duration_in_Minutes']:\n",
    "    print('There are total {} data which {} are less than lower limit.'.format(len(df[df[col] < dict['lower_limit_' + col]] ) , col))\n",
    "    print('There are total {} data which {} are more than upper limit.'.format(len(df[df[col] > dict['upper_limit_' + col]] ) , col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ce1d41",
   "metadata": {},
   "source": [
    "#### Capping Duration_in_Minutes with upper limit and lower limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers\n",
    "for col in ['Duration_in_Minutes']:\n",
    "    df[col] = np.where(\n",
    "        df[col] > dict['upper_limit_' + col],\n",
    "        dict['upper_limit_' + col],\n",
    "        np.where(\n",
    "            df[col] < dict['lower_limit_' + col],\n",
    "            dict['lower_limit_' + col],\n",
    "            df[col]  \n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e136a95",
   "metadata": {},
   "source": [
    "#### After Outliers treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4509490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 3 x 3 grid of subplots\n",
    "fig = plt.figure(figsize=[16,12])\n",
    "fig.suptitle('BOXPLOT After Outliers Handling', fontsize=18, fontweight='bold')\n",
    "fig.subplots_adjust(top=0.92);\n",
    "fig.subplots_adjust(hspace=0.5, wspace=0.4);\n",
    "for i ,col in enumerate( ['Duration_in_Minutes']):  \n",
    "    ax1 = fig.add_subplot(1, 1, i+1);\n",
    "    ax1 = sns.boxplot(data = df, x=col ,  color= colours[i]);\n",
    " \n",
    "    ax1.set_title(f'{col}', fontdict=axtitle_dict) \n",
    "    ax1.set_xlabel(f'{col}', fontdict=axlab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2fc5e",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Correlation Analysis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with output feature\n",
    "ax = round(df.corr()['Price'].sort_values(ascending = False)[1:] ,2 ).plot(kind = 'bar' ,color='dodgerblue' , figsize = (15,10))\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81258b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have dropped the feature which is not correlated with output feature\n",
    "df.drop('Vistara Premium economy',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1274b3cd",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Heatmap</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation matrix heatmap\n",
    "fig, ax = plt.subplots(figsize=[25,10])\n",
    "sns.heatmap(df.corr(), ax=ax,  annot=True, linewidths=0.05, fmt= '.2f',cmap='RdBu')\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax.set_title('Dataset Correlation Matrix', fontdict=axtitle_dict)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4b243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have dropped the one of feature having correlation coffecient more than 0.75 or less than -0.75\n",
    "df.drop('Source_Chennai',axis=1, inplace=True)\n",
    "df.drop('Source_Delhi',axis=1, inplace=True)\n",
    "df.drop('Source_Mumbai',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19245e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check final shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c098dc7",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Feature Scaling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3861868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divided the data into two part x and y. Where, x is independent variable and y is dependent variable or target variable \n",
    "x = df.drop(columns=['Price']).values  \n",
    "y = df['Price'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d306eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dataset into min_max scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = MinMaxScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e63ecb",
   "metadata": {},
   "source": [
    "## <span style=\"color:Blue\">Modelling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54059d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a16a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db64612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find mean absolute % error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c4e70",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Linear Regression</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a090b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f4bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Training:')\n",
    "print('R^2 Score:', lr.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9def8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Testing:')\n",
    "print('R^2 Score:',r2_score(y_test, y_pred))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Mean Absolute % Error: \", round(mean_absolute_percentage_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256cf49",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Polynomial Regression</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb764ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2)\n",
    "X_poly = poly.fit_transform(x)\n",
    "\n",
    "poly.fit(X_poly, y)\n",
    "lin2 = LinearRegression()\n",
    "lin2.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Training:')\n",
    "y_pred = lin2.predict(poly.fit_transform(X_test))\n",
    "y_pred_train = lin2.predict(poly.fit_transform(X_train))\n",
    "print('R^2 Score:', r2_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Testing:')\n",
    "print('R^2 Score:',r2_score(y_test, y_pred))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Mean Absolute % Error: \", round(mean_absolute_percentage_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf5b78",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Random Forest</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_rf = RandomForestRegressor()\n",
    "reg_rf.fit(X_train, y_train)\n",
    "y_pred = reg_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f50cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Training:')\n",
    "print('R^2 Score:', reg_rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcdd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Testing:')\n",
    "print('R^2 Score:',metrics.r2_score(y_test, y_pred))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"Mean absolute % error: \", round(mean_absolute_percentage_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e5e71",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Random Forest with Hyperparameter Tuning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14410f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# Search across 100 different combinations\n",
    "rf_random = RandomizedSearchCV(estimator = reg_rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2,n_jobs=-1,)\n",
    "rf_random.fit(X_train,y_train)\n",
    "\n",
    "# Best parameter\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f417bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = gcv_rf.predict(X_test)\n",
    "y_train_pred = gcv_rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4194d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Training:')\n",
    "print('R^2 Score:', r2_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda24a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(y_test, y_prediction, alpha = 0.5)\n",
    "plt.xlabel(\"y_test\")\n",
    "plt.ylabel(\"y_pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b64c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Testing:')\n",
    "print('R^2 Score:',metrics.r2_score(y_test, y_prediction))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_prediction))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_prediction))\n",
    "print(\"Mean Absolute % Error: \", round(mean_absolute_percentage_error(y_test, y_prediction)))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b381a9",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">XGB Regressor with Hyperparameter Tuning</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27007a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search CV\n",
    "param_grid = {'alpha': [0.9,0.09,0.1,0.7,0.05,0.125],'learning_rate':[0.75,0.5,0.25,0.1,0.01],\n",
    "              'max_depth':[2,3,4,5,6],'n_estimators':[125,110, 100, 90, 75]}\n",
    "xgb = XGBRegressor()\n",
    "gcv_xgb= GridSearchCV(xgb, param_grid, scoring='neg_mean_absolute_error',cv=5, n_jobs=5, verbose=True)\n",
    "res = gcv_xgb.fit(X_train,y_train)\n",
    "res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gcv_xgb.predict(X_train)\n",
    "y_test_pred = gcv_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fea65a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Training:')\n",
    "print('R^2 Score:',r2_score(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6455a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Testing:')\n",
    "print(\"R^2 Score: \", r2_score(y_test, y_test_pred))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_test_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_test_pred))\n",
    "print(\"Mean Absolute % Error: \", round(mean_absolute_percentage_error(y_test, y_test_pred)))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9506d230",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Weighted Average Ensemble</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from numpy import argsort\n",
    "# To get a list of best models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('Random Forest with Hyperparameter Tuning', rf_random))\n",
    "    models.append(('XGB Regressor with Hyperparameter Tuning', gcv_xgb))\n",
    "    return models\n",
    "# To evaluate each base model\n",
    "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    # Fit and evaluate the models\n",
    "    scores = list()\n",
    "    for name,model in models:\n",
    "        # Fit the model\n",
    "        model.fit(X_train,y_train)\n",
    "        # Evaluate the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test,y_pred)\n",
    "        # Store the performance\n",
    "        scores.append(r2)\n",
    "    return scores\n",
    "models = get_models()\n",
    "scores = evaluate_models(models, X_train, X_test, y_train, y_test)\n",
    "#print(scores)\n",
    "ranking = 1 + argsort(argsort(scores))\n",
    "#print(ranking)\n",
    "# Create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=ranking)\n",
    "# Fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In Training:')\n",
    "y_pred_train = ensemble.predict(X_train)\n",
    "print('Weighted R^2 Score: ' (r2_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = ensemble.predict(X_test)\n",
    "# Evaluate predictions\n",
    "print('Weighted R^2 Score: ' (r2_score(y_test, y_pred)))\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean Absolute % Error: \", round(mean_absolute_percentage_error(y_test, y_pred)))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc3a5b3",
   "metadata": {},
   "source": [
    "### <span style=\"color:forestgreen\">Prediction</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90445b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
